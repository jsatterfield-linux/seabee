{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<ul> <li>Doxygen documentation</li> <li>Rust crate documentation<ul> <li>bpf</li> <li>seabee</li> <li>tests</li> </ul> </li> </ul>"},{"location":"#demo","title":"Demo","text":"Terminal"},{"location":"architecture/","title":"Architecture","text":""},{"location":"architecture/#folder-map","title":"Folder Map","text":""},{"location":"architecture/#vscode","title":"<code>.vscode</code>","text":"<p>Contains the settings necessary for VSCode extensions and their configurations.</p>"},{"location":"architecture/#bpf","title":"<code>bpf</code>","text":"<p>This crate contains all BPF program code (<code>.bpf.c</code> and <code>.h</code>) and Rust interfaces   to interpret the data that comes from them in a ring buffer map. Utility functions useful for multiple programs should be stored under the   <code>bpf/include</code> folder as a header file. Do not write any BPF-related code other than BPF skeleton configuration outside   of this crate.</p>"},{"location":"architecture/#ci","title":"<code>ci</code>","text":"<p>Contains the configurations necessary to compile, lint, and test the code on a   GitLab CI runner. See its documentation for more info.</p>"},{"location":"architecture/#docs","title":"<code>docs</code>","text":"<p>Contains a majority of the high-level documentation for the project.</p>"},{"location":"architecture/#scripts","title":"<code>scripts</code>","text":"<p>Contains all of the shell scripts used for installation and configuring.</p>"},{"location":"architecture/#seabee","title":"<code>seabee</code>","text":"<p>Contains all the code specific to the SeaBee program.</p>"},{"location":"architecture/#tests","title":"<code>tests</code>","text":"<p>Contains all of the code and configurations necessary   to run integration tests against the code to ensure the capabilities   and protections offered by SeaBee actually work.</p>"},{"location":"capabilities/","title":"SeaBee Capabilities","text":"<p>This document exists as a way to track what the userspace program does   and what it still needs to do.</p>"},{"location":"capabilities/#threats-mitigated","title":"Threats mitigated","text":"<ul> <li>Block access to the userspace's eBPF maps via the <code>BPF_GET_FD_BY_ID</code> command     in the <code>security_bpf</code> LSM hook</li> <li>Block signals that would interrupt or terminate the userspace process group     via <code>security_task_kill</code></li> <li>Block unlinking of eBPF pinned programs via the <code>security_inode_unlink</code> LSM hook</li> <li>Block unmounting of <code>/sys</code> or <code>/sys/bpf</code> via the <code>security_sb_umount</code> LSM hook</li> <li>Block kernel module loading via the <code>security_kernel_read_file</code>,     <code>security_kernel_load_data</code>, and <code>security_kernel_module_request</code> LSM hooks</li> <li>Block ptrace of the userspace via the <code>security_ptrace_access_check</code> LSM hook</li> <li>Block killing a parent process of the userspace by running under systemd</li> </ul>"},{"location":"capabilities/#threats-investigated-and-dismissed","title":"Threats investigated and dismissed","text":"<ul> <li>Multiple eBPF programs on the same LSM hook cannot override a \"deny\" result</li> <li>Blocking eBPF pinned map access because the userspace's maps aren't pinned</li> <li>ptrace through <code>security_ptrace_traceme</code> is out of scope   since it is only invoked by a tracee and the userspace is not one</li> <li>The <code>bpf_send_signal</code> helper can only signal the <code>current</code> task</li> <li>uprobe attaching to the userspace process is not a concern as long as <code>bpf_probe_write_user</code> is blocked</li> </ul>"},{"location":"capabilities/#threats-addressed-by-other-tools","title":"Threats addressed by other tools","text":""},{"location":"capabilities/#threats-yet-to-be-addressed","title":"Threats yet to be addressed","text":"<ul> <li>Handle safe <code>security_kernel_module_request</code> calls for kernel modules</li> <li>Manipulating the BPF pinned programs through <code>sys_bpf</code><ul> <li>open, write, read, etc.</li> </ul> </li> <li>prevention of blocking our necessary permissions</li> <li>Integrate bpflock and lockdown LSM protections</li> <li>Does mounting BPFFS in a container/namespace cause the umount protections to fail?</li> <li>Prevent removing <code>bpf</code> from the LSM kernel command-line in the GRUB config</li> <li>Harden against hijacking of our userspace program after all eBPF stuff is loaded</li> <li>Provide mechanisms for other eBPF projects/programs to be protected</li> </ul>"},{"location":"ci/","title":"Continuous Integration Workflow","text":"<p>This guide explains the thoughts and considerations behind why the CI/CD   pipeline is setup the way it is.</p>"},{"location":"ci/#linting-formatting","title":"Linting &amp; Formatting","text":"<p>This is primarily provided by MegaLinter.</p> <p>Rust's clippy is supported by MegaLinter,   but the current project requires system dependencies in order to compile   the eBPF bytecode to embed inside the Rust code (see <code>build.rs</code>). This requires using a separate VM or container which has these dependencies.</p> <p>Rust's built-in formatter <code>cargo fmt</code> is not available in MegaLinter and is   therefore ran separately to check for style inconsistencies in <code>.rs</code> files.</p>"},{"location":"ci/#testing","title":"Testing","text":"<p>To run eBPF programs and the tests against them,   we need a sufficiently new enough kernel that has all of the features (v5.8+).</p> <p>To run a new enough kernel for a CI job (container or not),   we must provide our own VM for GitLab to run the job on.</p> <p>To run our own VM with the latest kernel,   we cannot deploy on EC2 due to the limited AMI options.</p> <p>To this end, Terraform is utilized to programmatically create   a VM on our own hardware through libvirt/QEMU and install the   GitLab Runner to accept and run jobs. Terraform by itself simply interacts with infrastructure providers to provision VMs.</p> <p>It is generally not recommended to allow GitLab CI jobs to change the state of the   underlying system that is running the GitLab Runner process. As a result,   Docker or Kubernetes is often used to run the job in a containerized environment. However, official Docker container providers (Ubuntu, Fendora, etc.) do not have the   project's system dependencies installed and have to be installed on each run. In order to not incur this overhead, a custom container image can be created. In our case, a custom Dockerfile can be used.</p>"},{"location":"ci/#implementation","title":"Implementation","text":"<p>Details about the Terraform configurations can be found   in its own repository.</p>"},{"location":"ci/#docker-image","title":"Docker Image","text":"<p>The <code>ci</code> folder contains a Dockerfile which will install all of the   dependencies necessary to compile, format, and document the Rust   code.</p> <p>This image should be built manually on your development workstation   and then uploaded to your Docker registry server under the name <code>build</code>.</p> <pre><code>docker build -t build -f ci/Dockerfile .\n</code></pre> <p>NOTE - If you are using a Docker mirror for base images, you need to use the   <code>--build-arg DOCKER_MIRROR=&lt;url&gt;</code> syntax to set it with a <code>/</code> at the end</p> <pre><code>docker build -t build -f ci/Dockerfile --build-arg DOCKER_MIRROR=your.docker.mirror:1234/ .\n</code></pre>"},{"location":"ci/#gitlab-ci-variables","title":"GitLab CI Variables","text":"<p>The following variables need to be set for the full CI pipeline to work</p>"},{"location":"ci/#docker_mirror","title":"DOCKER_MIRROR","text":"<p>Optional if you are using a Docker mirror to cache images.</p>"},{"location":"ci/#edit_uri","title":"EDIT_URI","text":"<p>The URI to use for generating direct links to edit the page in the source   code repository.</p>"},{"location":"ci/#repo_name","title":"REPO_NAME","text":"<p>The name of the repository to use in the generated documentation.</p>"},{"location":"ci/#repo_url","title":"REPO_URL","text":"<p>The full URL to the source code repository.</p>"},{"location":"ci/#site_url","title":"SITE_URL","text":"<p>The full URL to the GitLab Pages or other static web server that will host   the compiled documentation.</p> <p>The default uses the GitLab scheme, but for GitHub it will need to be changed.</p>"},{"location":"ci/#running","title":"Running","text":"<p>For Terraform, the ideal place to run private VMs are on your own infrastructure.</p> <p>After logging into your server, install Terraform by following the guide:</p> <ul> <li>Terraform Installation</li> </ul> <pre><code># Check out the Terraform scripts into a new directory\ngit clone &lt;repo_url&gt;\ncd terraform\n# Create a GitLab runner for the group if necessary\ncd gitlab_runner\nterraform init\nterraform apply\n</code></pre>"},{"location":"ci/#destroying","title":"Destroying","text":"<p>In the same folder that your <code>*.tfstate</code> files were created when you ran   <code>terraform apply</code>, you can run <code>terraform destroy</code> to have all resources   Terraform created to be deleted too.</p>"},{"location":"crypto/","title":"Cryptography in SeaBee","text":"<p>This document assumes you are running SeaBee with <code>-v</code> or <code>--verify-policy</code> option enabled. This option is enabled by default and is the only secure way to use SeaBee. This option enables signature verification on SeaBee policies, ensuring the authenticity and integrity of requests to update SeaBee policy. If this option is turned off, SeaBee provides no security guarantees, but will still verify signatures and report (but not block) on failure.</p>"},{"location":"crypto/#signed-policy-updates","title":"Signed Policy Updates","text":"<p>SeaBee uses digital signatures to sign and verify policy updates. A policy can only be updated when signed with the same key used when the policy was first added. This ensures that only a user with access to a private signing key should be able to update the SeaBee policy. This also requires that users add a key to SeaBee before adding a policy in order for the policy to be verified. SeaBee's threat model considers a malicious superuser or comprised process with root privileges in its scope. This means that the private signing key should exist on a secure system that is separate from the system where SeaBee  is deployed.</p>"},{"location":"crypto/#seabee-root-key","title":"SeaBee Root Key","text":"<p>SeaBee will require a public verification key on startup. This verification key is known as the \"root key\" because it is used to control the administration of SeaBee.</p> <p>TODO: document use cases for the root key (disable, runtime config change)</p> <p>If SeaBee runs with the <code>verify-keys</code> option, then all keys added to SeaBee must be signed by this root key. This allows a system administrator to control who can use SeaBee. The root key cannot be updated during the lifetime of SeaBee, It can only be chagned while SeaBee is turned off. This remains true even if <code>verify-keys</code> is disabled.</p> <p>If this option is disabled, then anyone can use SeaBee and add keys. This does not inherently represent an integrity problem since a policy update must be signed with the same key used to create the policy. However, if anyone is allowed to add keys, it may open the door for availability attacks. A file or binary cannot be tracked by two different SeaBee policies (see policy.md). This means that errors will occur if two different entities create conflicting SeaBee policies.</p> <p>Enabling this option allows control over who is creating SeaBee policies, but also adds a layer of complexity for using SeaBee since each user will have to obtain a signature from the root key.</p>"},{"location":"crypto/#seabeectl","title":"seabeectl","text":"<p>All updates will happen through the trusted binary <code>seabeectl</code>. If <code>-v</code> or <code>--verify-policy</code> is enabled in SeaBee's config (which is the only secure way to use SeaBee), then the following <code>seabeectl</code> operations require signatures:</p> <ul> <li>Adding a new policy: The policy yaml must be given alongside a valid signature for the file.</li> <li>Updating a policy: Update works exactly the same as add, except that the name of the policy should already exist in SeaBee. In order for an update to be accepted, the version number must be greater than the current policy version. You can view the current version with <code>seabeectl show</code> or <code>seabeectl list</code>.</li> <li>Removing a policy: A yaml file called a \"remove request\" must be passed along with a valid signature for this file. The \"remove request\" is a yaml file with only two fields: a name and a version.</li> <li>Removing a key: removing a key requires passing a path to the key file (pem) and a valid signature for that file. The signature must be verified using the key itself or the SeaBee root key. Removing a key does not automatically revoke any polices that were signed by that key. Instead, during reboot, all policies are reloaded and re-verified. The removal of a key may cause some policies to generate verification errors on reboot. The SeaBee root key cannot be removed, it can only be changed while SeaBee is turned off.</li> </ul> <p>Additionally, if <code>--verify-keys</code> is enabled, the following operations also require a signature</p> <ul> <li>Adding a key: adding a key requires passing the path of the key file (pem) and a valid signature for that file signed by the SeaBee root key.</li> </ul> <p>Use <code>seabeectl alg</code> to see a list of supported cryptographic algorithms or formats</p>"},{"location":"crypto/#generating-a-key-pair","title":"Generating a key pair","text":"<p>In production, keys should be generated on a separate system from where SeaBee is deployed.</p> <p>We recommend using <code>openssl</code> to generate keys. SeaBee only uses keys for digital signatures and verification. SeaBee accepts RSA or ECDSA keys and expects password protected .pem files.</p> <p>The following instructions are from the openssl wiki.</p> <p>generate an RSA private key with passphrase</p> <ul> <li><code>openssl genpkey -aes256 -algorithm RSA -pkeyopt rsa_keygen_bits:2048 -out rsa-private-key.pem</code></li> </ul> <p>generate an RSA public key</p> <ul> <li><code>openssl pkey -in rsa-private-key.pem -out rsa-public-key.pem -pubout</code></li> </ul> <p>generate an ECDSA private key with passphrase using NIST curve <code>P-256</code>. See NIST Recommendations for ECDSA curves.</p> <ul> <li><code>openssl genpkey -aes256 -algorithm EC -pkeyopt ec_paramgen_curve:P-256 -out ecdsa-private-key.pem</code></li> </ul> <p>generate an ECDSA public key</p> <ul> <li><code>openssl pkey -in ecdsa-private-key.pem -out ecdsa-public-key.pem -pubout</code></li> </ul>"},{"location":"crypto/#installing-the-seabee-root-key","title":"Installing the SeaBee Root Key","text":"<p>TODO: maybe make this a part of seabeectl?</p> <p>This step must be done before starting up SeaBee or it will generate an error.</p> <p><code>sudo cp ecdsa-public-key.pem /etc/seabee/seabee_root_key.pem</code></p>"},{"location":"crypto/#signing-a-seabee-policy","title":"Signing a SeaBee Policy","text":"<p><code>seabeectl</code> has a utility for signing SeaBee policies, but it is also possible to use <code>openssl</code>. We will use the ECDSA key from the previous section to do signing. By default, SeaBee expects the message digest to be <code>sha3-256</code>, but any <code>SHA2</code> or <code>SHA3</code> can be used by specifying it in the policy file or on the command line using <code>seabeectl sign -d</code></p> <p>Using <code>seabeectl</code></p> <ul> <li><code>sudo seabeectl sign -t test_policy.yaml -k ecdsa-private-key.pem -o signature.sign</code></li> </ul> <p>Using <code>openssl</code></p> <ul> <li><code>openssl dgst -sha3-256 -sign ecdsa-private-key.pem -out signature.sign test_policy.yaml</code></li> </ul>"},{"location":"crypto/#verifying-a-seabee-policy","title":"Verifying a SeaBee Policy","text":"<p>SeaBee will verify policies before they are loaded for the first time and whenever SeaBee receives a policy update. SeaBee will try to verify an update with each of its verification keys (recall that SeaBee is initialized with a verification key and updates can include additional verification keys). If all of SeaBee's keys fail to verify a policy update, then the update will be rejected. By default, SeaBee expects signatures to use a <code>sha3-256</code> message digest, but if the policy specifies another digest algorithm, then that algorithm will be used if SeaBee supports it.</p> <p>Using <code>openssl</code> to test verification of policy signatures</p> <ul> <li><code>openssl dgst -sha3-256 -verify ecdsa-public-key.pem -signature signature.sign test_policy.yaml</code></li> </ul> <p>Using <code>seabeectl</code> to test verification of policy signatures</p> <ul> <li><code>sudo seabeectl verify -t test_policy.yaml -k ecdsa-public-key.pem -s signature.sign</code></li> </ul>"},{"location":"implementation/","title":"Implementation Notes","text":""},{"location":"implementation/#bpf-naming-conventions","title":"BPF Naming Conventions","text":"<p>The BPF-to-Rust-skeleton compilation uses the name of the <code>.bpf.c</code> file     as the module name and prefixes for module functions. <code>my_bpf_program.bpf.c</code> will be converted into <code>mod MyBpfProgram;</code>   and <code>MyBpfProgramSkelBuilder</code> and other <code>MyBpfProgram...</code> prefixes.</p>"},{"location":"implementation/#logging","title":"Logging","text":"<p>So you've written up a new BPF program, that's great! Unfortunately, you've been using <code>bpf_printk</code> in your code. While this is nice for quick testing of your prototype,   it isn't a great long term solution. We want to have custom logs for your BPF program in a designated location. However, setting that up takes a couple steps. Don't worry though, it'll look great when we're done!</p>"},{"location":"implementation/#logging-a-new-bpf-hook","title":"Logging A New BPF Hook","text":"<ol> <li>Add a new entry to the <code>log_type</code> enum in <code>bpf/include/logging_types.h</code>.    This allows translation between the C log structs and the generated Rust log structs.</li> <li>Add a new struct in <code>bpf/include/logging_types.h</code> with the      name <code>*_log</code> where <code>*</code> is the name of the BPF program.    This struct describes any contextual info relevant to the hook.    At a minimum, it should contain the info used to make the access control decision.</li> <li>Create a logging function in <code>bpf/src/seabee_enforce/self_enforce_log.h</code>.    Follow the pattern of the other functions already present.    Instantiate the struct from step 2 and send it to the ringbuffer.    Use the <code>log_type</code> defined in the first step to aid the C-to-Rust translation.</li> <li>Replace <code>bpf_printk</code> calls with the new log function.    Choose a <code>reason</code> and a <code>level</code> for each call.    The <code>reason</code> explains why the log is being printed.    For example, <code>LOG_REASON_DENY</code>, suggests that some action was attempted and denied.    The <code>level</code> defines a relative level of importance of the log.    This allows some customization of how many logs are printed.    Typically only the most critical logs will be printed,      but if a problem is being debugged, including less important logs may be helpful.    In order to differentiate between different reasons and levels,      code may need to be restructured.</li> <li>Add the struct to the <code>get_log_struct</code> function in <code>bpf/src/logging/mod.rs</code>.    Following the pattern of other logs,      add a case to the match statment and include the new <code>log_type</code> enum value and log struct.    The <code>ToString</code> trait must also be implemented to print the log.    Follow the pattern of other structs in the file.    Note: The name of the struct and <code>log_type</code> need to match in Rust and C,       otherwise it will fail to compile.</li> </ol>"},{"location":"implementation/#logging-for-a-new-skel","title":"Logging for a new Skel","text":"<ul> <li>Setup logging in skeleton code (c code)<ul> <li><code>#include \"logging.h\"</code></li> <li>create a global variable for log level: <code>u32 log_level;</code></li> <li>add the ringbuf: <code>struct log_ringbuf log_ringbuf SEC(\".maps\");</code></li> </ul> </li> <li>Setup the userspace code<ul> <li>configure skeleton log level: <code>open_skel.bss_mut().log_level = ...</code>;</li> <li>configure skeleton ringbuf: <code>open_skel.maps().log_ringbuf().reuse_fd(&lt;original log ringbuf&gt;.as_fd())?;</code></li> </ul> </li> </ul>"},{"location":"logging/","title":"Logging Interpretation","text":""},{"location":"logging/#log-level-error","title":"Log Level Error","text":"<p>Indicates something unexpected, a problem or bug in the code</p>"},{"location":"logging/#log-level-warn","title":"Log Level Warn","text":"<p>Most commonly used when SeaBee blocks an action, correlates with security level 'blocked' in policy</p>"},{"location":"logging/#log-level-info","title":"Log Level Info","text":"<p>Prints useful, but not security-related information to the user. Also correlates with security level 'audit' in policy.</p>"},{"location":"logging/#log-level-debug","title":"Log Level Debug","text":"<p>Primarily identifies control flow to help debug where an error happens</p>"},{"location":"logging/#log-level-trace","title":"Log Level Trace","text":"<p>Similar to debug, but even more fine-grained</p>"},{"location":"policy/","title":"SeaBee Policy","text":""},{"location":"policy/#security-framework","title":"Security Framework","text":"<ul> <li>SeaBee provides isolation between eBPF applications via policy.</li> <li>Policy is defined for an executable or a set of executables (the policy scope)</li> <li>SeaBee detects when protected objects are created by a process in the policy scope and assigns them with the corresponding policy ID including the process itself</li> <li>Any executable or process will have access to all protected objects with the same Policy ID as itself, which indicates that it falls within the same scope.</li> <li>A SeaBee policy for an executable must be loaded before that executable starts in order for SeaBee to associate the exe path with the created process and protect eBPF objects for that process. When run as a systemd daemon(strongly recommended), SeaBee must still start before other daemon applications during boot. If an application using SeaBee starts early during boot, it must ensure that it starts after SeaBee (or add SeaBee as a dependency).</li> </ul>"},{"location":"policy/#definitions","title":"Definitions","text":"<ul> <li>Protected Object: anything that SeaBee protects including: processes, eBPF maps, pinned programs, or specific files.</li> <li>Policy ID: Each policy is assigned a Policy ID. The Policy ID is used to identify protected objects associated with the same policy. All objects in the same policy have the same Policy ID.</li> <li>Action: actions are defined in the policy config. The action determines how a process not governed by the policy should be allowed to interact with a particular protected object. The action can be different for each protected object. For example: \"maps: audit\" would audit, but allow any external process to access a map that is within the policy scope.</li> <li>Policy Config: A list of actions. The policy config determines how processes not governed by the policy scope can access protected objects within the policy scope. It assigns an Action for each protected object indicating how the external access should be handled.</li> </ul>"},{"location":"policy/#policy-expressiveness","title":"Policy Expressiveness","text":"<p>Think of a SeaBee policy as a list of \"deny\" or \"audit\" rules. By default, everything is allowed (this is the 'policy' if SeaBee is not being used). When a file path for an executable is listed under the \"scope\" for a SeaBee policy, the corresponding process is allowed to access any protected object it creates. The Policy Config determines how every other process not in policy scope is allowed to access those protected objects within the policy scope.</p> <p>When answering \"Is some process allowed to access some object?\", SeaBee considers two things:</p> <ol> <li>Does the process have the same Policy ID (scope) as the object?</li> <li>If not, does the policy config for the object's policy have an 'audit' or 'allow' action? Since these actions grant access to an external process.</li> </ol> <p>Actions in the Policy Config are only granular to the class of protected object not to each particular object. This means that you cannot have one map that is 'audit' and a different map that is 'block' for the same policy scope/executable.</p>"},{"location":"policy/#example-use-case","title":"Example Use Case","text":"<ul> <li>A can access all of its objects and none of B's objects.</li> <li>B can access all of its objects and none of A's objects.</li> </ul> <p>for testing/debugging, an action could be changed to 'audit' or bpftool could be added to the policy scope</p>"},{"location":"policy/#policy-anatomy","title":"Policy Anatomy","text":"<p>a policy has four parts: scope, config, hash, and signature</p>"},{"location":"policy/#scope","title":"Scope","text":"<ul> <li>a file path, determines which binaries the policy applies to</li> </ul>"},{"location":"policy/#config","title":"Config","text":"<ul> <li>determines what protections this policy provides within the <code>scope</code></li> <li><code>files</code> in this section determine how files are protected by the policy it may be the case that there are repeated files between <code>scope</code> and <code>config</code>. This would be the case if you wanted to prevent an executable from being modified and allow a process created by that executable permissions to access other objects in the policy.</li> </ul>"},{"location":"policy/#version","title":"Version","text":"<ul> <li>the version should be incremented when a policy is updated. The version ensures that an attacker cannot downgrade the policy to an old version or maliciously update a policy.</li> </ul>"},{"location":"policy/#examples","title":"Examples","text":"<p>test policies can be seen at <code>tests/policies</code></p>"},{"location":"testing/","title":"Testing Philosphy","text":""},{"location":"testing/#attack-surface","title":"Attack Surface","text":"<p>The system is made up of several parts and attacks are considered against each of them.</p> <ol> <li>Userspace process</li> <li>eBPF programs &amp; pins</li> <li>eBPF maps</li> <li>Attacks that circumvent the access control model</li> </ol>"},{"location":"testing/#test-goals","title":"Test Goals","text":"<ol> <li>Correct functionality: the system works as desired</li> <li>Safety: the system is protected from adversaries<ul> <li>Malicious root processes</li> <li>Other eBPF programs</li> </ul> </li> </ol>"},{"location":"testing/#test-filtering","title":"Test Filtering","text":"<p>If you are having trouble with a particular test and only want to run it   or a subset of tests, then you can use a filter on the command line.</p> <p>For instance, when in the <code>seabee</code> folder:</p> <pre><code>export CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_RUNNER='sudo -E'\ncargo test --test integration_test -- &lt;filter&gt;\n</code></pre> <p>Where <code>&lt;filter&gt;</code> is replaced by the name of the test you want to run,   i.e. <code>security_kmod</code>.</p> <p>Similarly, if you need to skip a test because it has a known failure,   you can skip it using the <code>--skip &lt;filter&gt;</code> option:</p> <pre><code>export CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_RUNNER='sudo -E'\ncargo test --test integration_test -- --skip &lt;filter&gt;\n</code></pre>"},{"location":"testing/#test-structure","title":"Test Structure","text":""},{"location":"testing/#testsuite-trait-and-derivatives","title":"TestSuite trait (and derivatives)","text":"<p>Located under <code>tests/src/suite.rs</code></p> <p>This trait has been developed to closely mimic how Pytest fixtures work. All tests should try to use the <code>TestSuite</code> structure when possible as it   has the infrastructure necessary to provide shared state between tests   via its <code>get_args()</code> function. The exception are simple tests and tests that don't need shared state   such as the Daemon and Fork tests.</p> <p>There are currently three implementations of TestSuite:</p> <ul> <li><code>seabee/tests/functional/mod.rs</code></li> <li><code>seabee/tests/security/mod.rs</code></li> <li><code>tests/src/functional/mod.rs</code></li> </ul>"},{"location":"testing/#bpfstate","title":"BPFState","text":"<p>Located under <code>tests/src/state/mod.rs</code></p> <p><code>BPFState</code> is a generic structure that has been defined to summarize   information gleaned from a BPF userspace including maps and pins.</p> <p>The default <code>TestArgs</code> structure in <code>TestSuite</code> contains three instances of   <code>BPFState</code>:</p> <ul> <li>Rust - Information from the perspective of a BPF file-descriptor owner</li> <li>Linux - Information from the perspective of a Linux superuser</li> <li>Ground Truth - Information provided by the test writer</li> </ul> <p>The <code>check_args()</code> function in the <code>TestSuite</code> trait will check whether the   <code>BPFState</code> was manipulated during the tests.</p>"},{"location":"testing/#generic-functional-tests","title":"Generic Functional Tests","text":"<p>Located under <code>tests/src/functional/mod.rs</code></p> <p>A generic functional test library has been developed under <code>tests/src/functional</code>. Any BPF userspace can run these tests so long as they use the <code>BPFUserspace</code>   structure defined in the <code>bpf</code> crate. They also depend on ground truth to be defined in a TOML file, see the   <code>seabee/tests/ground_truth.toml</code> for an example.</p> <p>The following types of tests are implemented for checking correct functionality:</p> <ul> <li>Maps<ul> <li>Existence</li> <li>Contents</li> </ul> </li> <li>Pins<ul> <li>Existence</li> <li>Correct directory</li> <li>Contents</li> </ul> </li> <li>Userspace<ul> <li>Existence</li> </ul> </li> </ul>"},{"location":"testing/#seabee","title":"SeaBee","text":"<p>Integration tests are defined in <code>seabee/tests/integration_tests.rs</code>.</p>"},{"location":"testing/#daemon","title":"Daemon","text":"<p>Daemon tests are in <code>seabee/tests/daemon_test.rs</code> and ran separately from the   tests defined in <code>seabee/tests/integration_tests.rs</code>.</p> <p>These tests verify properties specific to <code>systemd</code>.</p>"},{"location":"testing/#functional","title":"Functional","text":"<p>Correct functionality is tested via the generic functional tests which   is extended via a SeaBee specific TestSuite defined under   <code>seabee/tests/functional/mod.rs</code> which includes a test to   check that the correct inode and device id information is used within   the <code>protected_pins</code> map.</p>"},{"location":"testing/#security","title":"Security","text":"<p>Safety is tested via the SeaBee security tests located under   <code>seabee/tests/security/mod.rs</code>. These tests verify that the userspace and associated BPF programs and maps cannot be manipulated once the SeaBee protections are in place.</p>"},{"location":"threat_model/","title":"Threat Model","text":"<p>An important question with any security project is to define the threat model:</p> <p>What are we trying to protect from and what are we not trying to protect.</p> <p>This project aims to protect a userspace process   and its eBPF programs from a variety of attacks:</p> <ul> <li>Signals that would kill the userspace program</li> <li>Ptracing the userspace program</li> <li>Unauthorized eBPF map access and manipulation</li> <li>Deletion of pinned eBPF programs and eBPF maps</li> <li>Trusted loading of kernel modules*</li> </ul> <p>Some attack types are currently outside the scope of this project:</p> <ul> <li>Disabling systemd service at boot:<ul> <li><code>sudo systemctl disable seabee &amp;&amp; sudo reboot</code></li> </ul> </li> <li>Disabling the BPF LSM module at boot:<ul> <li>GRUB modification</li> <li>Kernel command-line modification</li> </ul> </li> </ul>"}]}